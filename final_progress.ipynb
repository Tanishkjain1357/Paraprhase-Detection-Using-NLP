{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paraphrase Detection**: To successfully compare two different text entities and to check if they have a similar meaning or not. We will be assuming that the sentences are in the English language. \n",
    "\n",
    "**Research Questions**\n",
    "How can we check if two different text entities have the same meaning or not, using NLP?\n",
    "What could be the applications of this task?\n",
    "What are examples of paraphrase detection already being used in real life?\n",
    "\n",
    "A prominent example of paraphrase detection seen consistently in everyday life is a plagiarism detector, like the tool Turnitin, used by many schools to determine if a student's assigment is original content or if it had been plagiarised. Essentially following the definition of paraphrase detection, a plagiarism detector like Turnitin would scour the corpus, in this case an assignment that a student had submitted and determine if it contained similar words to other published works. This could also assist in finding synonyms and ideally antonyms for certain words in text, which is similar to the app Grammarly.\n",
    "\n",
    "**Datasets**\n",
    "Sentence Label Sentence: Labels are either true or false.\n",
    "* Microsoft Research Paraphrase: \n",
    "    * This contains 5800 pairs of sentences that have been extracted from news sources on the web \n",
    "    * This dataset has been human-annotated\n",
    "        * Looks at whether each pair captures a paraphrase/semantic equivalence relationship\n",
    "* TwitterPPDB corpus:\n",
    "    * This consists of 51,524 pairs of sentence-level paraphrases from Twitter by linking tweets through shared URLs. \n",
    "    * This corpus is human-annotated.\n",
    "    * It can grow 30,000 new sentential paraphrases per month with ~70% precision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/msr_paraphrase_corpus/msr_paraphrase_train.txt', sep = \"\\t\", \n",
    "                header = None, names = ['class', 'id1', 'id2', 'text1', 'text2']) \n",
    "train_data = train_data.drop([0])\n",
    "train_data['text'] = train_data['text1']+' '+train_data['text2']\n",
    "train_data.drop(['id1', 'id2'], axis = 1, inplace = True) \n",
    "train_data = train_data.dropna()\n",
    "train_data['class'] = train_data['class'].apply(lambda x: int(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_data = pd.read_csv('data/msr_paraphrase_corpus/msr_paraphrase_test.txt', sep = \"\\t\", \n",
    "                            header = None, names = ['class', 'id1', 'id2', 'text1', 'text2']) \n",
    "test_data = test_data.drop([0])\n",
    "test_data['text'] = test_data['text1']+' '+test_data['text2']\n",
    "test_data.drop(['id1', 'id2'], axis = 1, inplace = True) \n",
    "test_data = test_data.dropna()\n",
    "test_data['class'] = test_data['class'].apply(lambda x: int(x))\n",
    "\n",
    "final_data = pd.concat([train_data, test_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok_helper(word):\n",
    "    word.lower()\n",
    "    word = word.replace(\".\",\"\").replace(\",\",\"\")\n",
    "    return word.lower()\n",
    "\n",
    "def lemma_tokenizer(text):\n",
    "    wpt = WordPunctTokenizer()\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(tok_helper(w)) for w in wpt.tokenize(text) if w not in stopwords.words('english')]\n",
    "\n",
    "\n",
    "# classifier.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6630103595368677\n"
     ]
    }
   ],
   "source": [
    "# Word Overlap\n",
    "def predict_overlap(t1, t2):\n",
    "    t1_tok = set(lemma_tokenizer(t1))\n",
    "    t2_tok = set(lemma_tokenizer(t2))\n",
    "    common = t1_tok.intersection(t2_tok)\n",
    "    return len(common) / len(t1_tok.union(t2_tok)) > 0.5\n",
    "\n",
    "over_pred = []\n",
    "for index, row in test_data.iterrows():\n",
    "    over_pred.append(predict_overlap(row['text1'], row['text2']))\n",
    "\n",
    "c = (list(over_pred == test_data['class'].values)).count(True)\n",
    "acc = c/len(over_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6489945155393053"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LogReg\n",
    "vectorizer = CountVectorizer(tokenizer=lemma_tokenizer)\n",
    "final_vector = vectorizer.fit_transform(final_data['text']) \n",
    "\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(final_vector[:3941], train_data['class'].values)\n",
    "\n",
    "classifier.score(final_vector[3941:],test_data['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ameyajain/.local/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:489: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4673979280926264\n"
     ]
    }
   ],
   "source": [
    "# N-gram overlap\n",
    "n_gram_count = CountVectorizer(tokenizer=lemma_tokenizer, ngram_range=(1,3))\n",
    "def predict_overlap_n(t1, t2):\n",
    "    t1_tok = set(n_gram_count.fit([t1]).vocabulary_)\n",
    "    t2_tok = set(n_gram_count.fit([t2]).vocabulary_)    \n",
    "    common = t1_tok.intersection(t2_tok)\n",
    "    return len(common) / len(t1_tok.union(t2_tok)) > 0.5\n",
    "\n",
    "over_pred = []\n",
    "for index, row in test_data.iterrows():\n",
    "    over_pred.append(predict_overlap_n(row['text1'], row['text2']))\n",
    "\n",
    "c = (list(over_pred == test_data['class'].values)).count(True)\n",
    "acc = c/len(over_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.39      0.43       549\n",
      "           1       0.72      0.78      0.75      1092\n",
      "\n",
      "    accuracy                           0.65      1641\n",
      "   macro avg       0.59      0.59      0.59      1641\n",
      "weighted avg       0.64      0.65      0.64      1641\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "preds = classifier.predict(final_vector[3941:])\n",
    "report = metrics.classification_report(test_data['class'], preds, target_names=['0','1'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame constructor not properly called!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1032/2176877015.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DataFrame constructor not properly called!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;31m# Argument 1 to \"ensure_index\" has incompatible type \"Collection[Any]\";\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame constructor not properly called!"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(report).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Timeline**\n",
    "\n",
    "* Nov 29th - Add more datasets if found\n",
    "* Dec 8th  - Rework NLP Model to increase accuracy\n",
    "* Dec 10th - Build slides (up till initial creation of model)\n",
    "* Dec 13th - Report work to be comepleted\n",
    "* Dec 15th - Check, fix, extra finishing touches\n",
    "* Dec 16th - Buffer day + submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Work Allocation**\n",
    "\n",
    "* Tanishk Jain   : Research on NLP models to improve accuracy, start on slides\n",
    "* Ameya Jain     : Research on NLP models to improve accuracy, start on report\n",
    "* Shubh Vashisht : Appending to current NLP model, improve accuracy with feature manipulation, start on slides + report\n",
    "* Abhi Chalasani : Appending to current NLP Model, find datasets if possible, start working on slides and report\n",
    "\n",
    "Essentially, all of the deadlines listed above are the same for everyone. As we are all building off of each others' work, the sole foundational deadline would be the ones mentioned above to commence the next portion (report + slides)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
