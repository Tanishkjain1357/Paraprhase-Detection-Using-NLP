{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paraphrase Detection**: To successfully compare two different text entities and to check if they have a similar meaning or not. We will be assuming that the sentences are in the English language. \n",
    "\n",
    "**Research Questions**\n",
    "How can we check if two different text entities have the same meaning or not, using NLP?\n",
    "What could be the applications of this task?\n",
    "What are examples of paraphrase detection already being used in real life?\n",
    "\n",
    "**Datasets**\n",
    "Sentence Label Sentence: Labels are either true or false.\n",
    "* Microsoft Research Paraphrase: \n",
    "    * This contains 5800 pairs of sentences that have been extracted from news sources on the web \n",
    "    * This dataset has been human-annotated\n",
    "        * Looks at whether each pair captures a paraphrase/semantic equivalence relationship\n",
    "* TwitterPPDB corpus:\n",
    "    * This consists of 51,524 pairs of sentence-level paraphrases from Twitter by linking tweets through shared URLs. \n",
    "    * This corpus is human-annotated.\n",
    "    * It can grow 30,000 new sentential paraphrases per month with ~70% precision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/msr_paraphrase_corpus/msr_paraphrase_train.txt', sep = \"\\t\", header = None, names = ['class', 'id1', 'id2', 'text1', 'text2']) \n",
    "train_data = train_data.drop([0])\n",
    "train_data['text'] = train_data['text1']+' '+train_data['text2']\n",
    "train_data.drop(['id1', 'id2'], axis = 1, inplace = True) \n",
    "train_data = train_data.dropna()\n",
    "train_data['class'] = train_data['class'].apply(lambda x: int(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_data = pd.read_csv('data/msr_paraphrase_corpus/msr_paraphrase_test.txt', sep = \"\\t\", header = None, names = ['class', 'id1', 'id2', 'text1', 'text2']) \n",
    "test_data = test_data.drop([0])\n",
    "test_data['text'] = test_data['text1']+' '+test_data['text2']\n",
    "test_data.drop(['id1', 'id2'], axis = 1, inplace = True) \n",
    "test_data = test_data.dropna()\n",
    "test_data['class'] = test_data['class'].apply(lambda x: int(x))\n",
    "\n",
    "final_data = pd.concat([train_data, test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tok_helper(word):\n",
    "    word = word.replace(\".\",\"\").replace(\",\",\"\")\n",
    "    return word\n",
    "\n",
    "def lemma_tokenizer(text):\n",
    "    wpt = WordPunctTokenizer()\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(tok_helper(w)) for w in wpt.tokenize(text) if w not in stopwords.words('english')]\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=lemma_tokenizer)\n",
    "final_vector = vectorizer.fit_transform(final_data['text']) \n",
    "\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(final_vector[:3941], train_data['class'].values)\n",
    "# classifier.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5582, 14348)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(final_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_vector = vectorizer.transform(test_data['text'])\n",
    "# final_vector[3941:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = classifier.predict(final_vector[3941:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6489945155393053"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(final_vector[3941:],test_data['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "report = metrics.classification_report(test_data['class'], preds, target_names=['0','1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.47      0.39      0.43       549\\n           1       0.72      0.78      0.75      1092\\n\\n    accuracy                           0.65      1641\\n   macro avg       0.59      0.59      0.59      1641\\nweighted avg       0.64      0.65      0.64      1641\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Timeline**\n",
    "\n",
    "* Add more datasets if found - by Nov 29th\n",
    "* Rework NLP Model to increase accuracy - by Dec 8th\n",
    "* Build slides (up till initial creation of model) - by Dec 10th\n",
    "* Report work to be comepleted - by Dec 13th\n",
    "* Check, fix, extra finishing touches - by Dec 15th\n",
    "* Buffer day + submit - Dec 16th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Work Allocation**\n",
    "\n",
    "* Tanishk Jain: Research on NLP models to improve accuracy, start on slides\n",
    "* Ameya Jain: Research on NLP models to improve accuracy, start on report\n",
    "* Shubh Vashisht: Appending to current NLP model, improve accuracy with feature manipulation, start on slides + report\n",
    "* Abhi Chalasani: Appending to current NLP Model, find datasets if possible, start working on slides and report\n",
    "\n",
    "Overall all deadlines are the same for everyone. Since we are all building off each others' work, the only basic deadline would be the deadlines mentioned above to start onto the next portion (report + slides)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
